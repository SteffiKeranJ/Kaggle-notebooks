{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8f5a95a",
   "metadata": {},
   "source": [
    "%%bash\n",
    "\n",
    "unzip train.tsv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95cb0177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PhraseId  SentenceId                                             Phrase  \\\n",
       "0         1           1  A series of escapades demonstrating the adage ...   \n",
       "1         2           1  A series of escapades demonstrating the adage ...   \n",
       "2         3           1                                           A series   \n",
       "3         4           1                                                  A   \n",
       "4         5           1                                             series   \n",
       "\n",
       "   Sentiment  \n",
       "0          1  \n",
       "1          2  \n",
       "2          2  \n",
       "3          2  \n",
       "4          2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.tsv', sep='\\t')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70068028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PhraseId  SentenceId                                             Phrase\n",
      "0    156061        8545  An intermittently pleasing but mostly routine ...\n",
      "1    156062        8545  An intermittently pleasing but mostly routine ...\n",
      "2    156063        8545                                                 An\n",
      "3    156064        8545  intermittently pleasing but mostly routine effort\n",
      "4    156065        8545         intermittently pleasing but mostly routine\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv('test.tsv', sep='\\t')\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f57c5bc",
   "metadata": {},
   "source": [
    "## Sentiment Labels\n",
    "\n",
    "0 - negative\n",
    "1 - somewhat negative\n",
    "2 - neutral\n",
    "3 - somewhat positive\n",
    "4 - positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7ba5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['Sentiment'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12144c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhraseId</th>\n",
       "      <th>SentenceId</th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>This quiet , introspective and entertaining in...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>Even fans of Ismail Merchant 's work , I suspe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>4</td>\n",
       "      <td>A positively thrilling combination of ethnogra...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>Aggressive self-glorification and a manipulati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PhraseId  SentenceId                                             Phrase  \\\n",
       "0           1           1  A series of escapades demonstrating the adage ...   \n",
       "63         64           2  This quiet , introspective and entertaining in...   \n",
       "81         82           3  Even fans of Ismail Merchant 's work , I suspe...   \n",
       "116       117           4  A positively thrilling combination of ethnogra...   \n",
       "156       157           5  Aggressive self-glorification and a manipulati...   \n",
       "\n",
       "     Sentiment  \n",
       "0            1  \n",
       "63           4  \n",
       "81           1  \n",
       "116          3  \n",
       "156          1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDeDuped = train.drop_duplicates(subset=['SentenceId'], keep='first')\n",
    "trainDeDuped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835e1b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54c8c04d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((156060, 50), (156060, 50))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "Xids = np.zeros((len(train), 50))\n",
    "Xmask = np.zeros((len(train), 50))\n",
    "\n",
    "Xids.shape, Xmask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3403330d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, sequence in enumerate(train[\"Phrase\"]):\n",
    "    tokens = tokenizer.encode_plus(sequence, max_length=50, \n",
    "                               truncation=True, padding=\"max_length\",\n",
    "                               add_special_tokens=True, return_token_type_ids=False,\n",
    "                               return_attention_mask=True, return_tensors=\"tf\"\n",
    "                              )\n",
    "    Xids[i, :], Xmask[i, :] = tokens[\"input_ids\"], tokens[\"attention_mask\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c35e743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phrase</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A series of escapades demonstrating the adage ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>series</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156055</th>\n",
       "      <td>Hearst 's</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156056</th>\n",
       "      <td>forced avuncular chortles</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156057</th>\n",
       "      <td>avuncular chortles</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156058</th>\n",
       "      <td>avuncular</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156059</th>\n",
       "      <td>chortles</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156060 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Phrase  Sentiment\n",
       "0       A series of escapades demonstrating the adage ...          1\n",
       "1       A series of escapades demonstrating the adage ...          2\n",
       "2                                                A series          2\n",
       "3                                                       A          2\n",
       "4                                                  series          2\n",
       "...                                                   ...        ...\n",
       "156055                                          Hearst 's          2\n",
       "156056                          forced avuncular chortles          1\n",
       "156057                                 avuncular chortles          3\n",
       "156058                                          avuncular          2\n",
       "156059                                           chortles          2\n",
       "\n",
       "[156060 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train[['Phrase','Sentiment']]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b23269a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         seri escapad demonstr adag good goos also good...\n",
       "1                      seri escapad demonstr adag good goos\n",
       "2                                                      seri\n",
       "4                                                      seri\n",
       "5                           escapad demonstr adag good goos\n",
       "                                ...                        \n",
       "156055                                               hearst\n",
       "156056                                forc avuncular chortl\n",
       "156057                                     avuncular chortl\n",
       "156058                                            avuncular\n",
       "156059                                               chortl\n",
       "Name: Phrase, Length: 154674, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phrase = train_df['Phrase']\n",
    "phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f694fc77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         2\n",
       "2         2\n",
       "4         2\n",
       "5         2\n",
       "         ..\n",
       "156055    2\n",
       "156056    1\n",
       "156057    3\n",
       "156058    2\n",
       "156059    2\n",
       "Name: Sentiment, Length: 154674, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment = train_df['Sentiment']\n",
    "sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "376fc6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (3.4.4)\r\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages (from nltk) (1.15.0)\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eabded14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4135ae7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5a23666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TextPreprocessing(text):\n",
    "    text=str(text)\n",
    "    text = text.replace(\"'\",\"\")\n",
    "    tokenized_train_data = text_to_word_sequence(text,filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',split=\" \")\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stopwordremove = [i for i in tokenized_train_data if not i in stop_words]\n",
    "    stopwordremove_text = ' '.join(stopwordremove)\n",
    "    numberRemove = ''.join(num for num in stopwordremove_text if not num.isdigit())\n",
    "    stemmer = PorterStemmer()\n",
    "    stem_input = nltk.word_tokenize(numberRemove)\n",
    "    stem_text = ' '.join([stemmer.stem(word) for word in stem_input])\n",
    "    return stem_text.lower()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5199dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         A series of escapades demonstrating the adage ...\n",
       "1         A series of escapades demonstrating the adage ...\n",
       "2                                                  A series\n",
       "3                                                         A\n",
       "4                                                    series\n",
       "                                ...                        \n",
       "156055                                            Hearst 's\n",
       "156056                            forced avuncular chortles\n",
       "156057                                   avuncular chortles\n",
       "156058                                            avuncular\n",
       "156059                                             chortles\n",
       "Name: Phrase, Length: 156060, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train['Phrase'].copy()\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f37976ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "train_df['Phrase'] = train_df['Phrase'].apply(TextPreprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b95dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/pandas/core/series.py:4582: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  method=method,\n",
      "/home/ec2-user/anaconda3/envs/amazonei_tensorflow2_p36/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "train_df['Phrase'].replace('',np.nan,inplace =True)\n",
    "train_df.dropna(subset = ['Phrase'],inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b26397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x,test_x,train_y,test_y = train_test_split(phrase,sentiment,test_size=0.2,random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac2a3697",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_text = vectorizer.fit_transform(train_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "572a3c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Nearest Neighbour Train Accuracy Score : 73% \n",
      "K-Nearest Neighbour Test Accuracy Score  : 61% \n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                ('knn', KNeighborsClassifier(n_neighbors=5, metric='euclidean')),\n",
    "               ])\n",
    "\n",
    "knn.fit(train_x, train_y)\n",
    "\n",
    "test_predict = knn.predict(test_x)\n",
    "\n",
    "train_accuracy = round(knn.score(train_x, train_y)*100)\n",
    "test_accuracy =round(accuracy_score(test_predict, test_y)*100)\n",
    "\n",
    "print(\"K-Nearest Neighbour Train Accuracy Score : {}% \".format(train_accuracy ))\n",
    "print(\"K-Nearest Neighbour Test Accuracy Score  : {}% \".format(test_accuracy ))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52913e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Phrase'] = test['Phrase'].apply(TextPreprocessing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8fcc322",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = test['PhraseId']\n",
    "test_text = test['Phrase']\n",
    "y_prdict = knn.predict(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49c97f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(test_id, y_prdict)),\n",
    "               columns =['PhraseId', 'Sentiment'])\n",
    "submission.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50776c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_amazonei_tensorflow2_p36",
   "language": "python",
   "name": "conda_amazonei_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
